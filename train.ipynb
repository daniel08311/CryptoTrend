{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1331,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import sys\n",
    "import keras\n",
    "\n",
    "import os\n",
    "# mingw_path = 'C:\\\\Program Files\\\\mingw-w64\\\\x86_64-7.1.0-posix-seh-rt_v5-rev0\\\\mingw64\\\\bin'\n",
    "# os.environ['PATH'] = mingw_path + ';' + os.environ['PATH']\n",
    "import xgboost as xgb\n",
    "    \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv(\"btc_train.csv\")\n",
    "# train_df = pd.read_csv(\"eth_bitfinex.csv\")\n",
    "train_df = pd.read_csv(\"eth_binance.csv\")\n",
    "train_df = train_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1333,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_raw = train_df[\"ohlcv_close\"].values\n",
    "x_raw = train_df.drop(['time', 'last_price', 'ohlcv_close'], axis=1).values\n",
    "# x_raw = scaler.fit_transform(x_raw)\n",
    "\n",
    "log_count = len(y_raw)\n",
    "feats = len(x_raw[0])\n",
    "shift = 100\n",
    "shift_y = 100\n",
    "x_train = np.zeros((log_count-shift-shift_y,shift,feats))\n",
    "y_train = np.zeros(log_count-shift-shift_y)\n",
    "y_train_trend = np.zeros(log_count-shift-shift_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1334,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(log_count-shift_y-shift):\n",
    "    x_train[i] = x_raw[i:i+shift]\n",
    "    y_train[i] = y_raw[i+shift+shift_y]\n",
    "    diff = y_raw[i+shift+shift_y]-y_raw[i+shift]\n",
    "    if diff/y_raw[i+shift] > 0.01 :\n",
    "        y_train_trend[i] = 0\n",
    "        \n",
    "    elif diff/y_raw[i+shift] < -0.01:\n",
    "        y_train_trend[i] = 1\n",
    "        \n",
    "    else:\n",
    "        y_train_trend[i] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1335,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class0 = 221\n",
      "class1 = 242\n",
      "class2 = 10713\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(\"class{} = {}\".format(i,sum(y_train_trend==i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1336,
   "metadata": {},
   "outputs": [],
   "source": [
    "cla_0 = [idx for idx,i in enumerate(y_train_trend) if i == 0]\n",
    "cla_1 = [idx for idx,i in enumerate(y_train_trend) if i == 1]\n",
    "cla_2 = [idx for idx,i in enumerate(y_train_trend) if i == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1337,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "cla_2_idx = resample(cla_2, n_samples=1000, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1338,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.vstack((x_train[cla_0],x_train[cla_1],x_train[cla_2_idx]))\n",
    "y_train_trend = np.hstack((y_train_trend[cla_0],y_train_trend[cla_1],y_train_trend[cla_2_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1339,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_xgb = x_train.reshape(-1, x_train.shape[1]*x_train.shape[2])\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train_trend, y_test_trend = train_test_split(x_train_xgb, y_train_trend, test_size=0.2, random_state=42)\n",
    "\n",
    "# split = int(x_train_xgb.shape[0]*0.8)\n",
    "# x_test = x_train_xgb[split:]\n",
    "# y_test = y_train[split:]\n",
    "# y_test_trend = y_train_trend[split:]\n",
    "# x_train = x_train_xgb[:split]\n",
    "# y_train = y_train[:split]\n",
    "# y_train_trend = y_train_trend[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323\n",
      "[[ 36   0   3]\n",
      " [  0  52   0]\n",
      " [  2   0 200]]\n",
      "0.9742397520175298\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "rf = RandomForestClassifier(n_estimators=500, max_depth=12, random_state=0, n_jobs=4)\n",
    "rf.fit(x_train, y_train_trend)\n",
    "# RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=2,\n",
    "#            max_features='auto', max_leaf_nodes=None,\n",
    "#            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "#            min_samples_leaf=1, min_samples_split=2,\n",
    "#            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
    "#            oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "print(sum(rf.feature_importances_>0.001))\n",
    "print(confusion_matrix(rf.predict(x_test), y_test_trend))\n",
    "print(f1_score(rf.predict(x_test), y_test_trend, average='macro')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "dtest = xgb.DMatrix(x_test, label=y_test)\n",
    "\n",
    "params = {\"objective\": \"reg:linear\", \"booster\":\"gbtree\", 'max_depth':'2', 'eta':'0.0025', 'subsample':'0.7', 'eval_metric':'mae' , 'verbose':1}\n",
    "params['nthread'] = 3  \n",
    "evallist  = [(dtest,'eval')]\n",
    "num_round = 1500\n",
    "gbm_1 = xgb.train(params, dtrain, num_round, evallist)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = x_train[:,rf.feature_importances_>0.00]\n",
    "b = x_test[:,rf.feature_importances_>0.000]\n",
    "dtrain = xgb.DMatrix(a, label=y_train)\n",
    "dtest = xgb.DMatrix(b, label=y_test)\n",
    "\n",
    "params = {\"objective\": \"reg:linear\", \"booster\":\"gbtree\", 'max_depth':'2', 'eta':'0.003', 'subsample':'0.7', 'eval_metric':'mae' , 'verbose':1}\n",
    "params['nthread'] = 3  \n",
    "evallist  = [(dtrain,'eval'),(dtest,'eval')]\n",
    "num_round = 1440\n",
    "gbm_1 = xgb.train(params, dtrain, num_round, evallist)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-mlogloss:1.09776\n",
      "[1]\teval-mlogloss:1.09694\n",
      "[2]\teval-mlogloss:1.09611\n",
      "[3]\teval-mlogloss:1.09529\n",
      "[4]\teval-mlogloss:1.09447\n",
      "[5]\teval-mlogloss:1.09361\n",
      "[6]\teval-mlogloss:1.09278\n",
      "[7]\teval-mlogloss:1.092\n",
      "[8]\teval-mlogloss:1.09123\n",
      "[9]\teval-mlogloss:1.09039\n",
      "[10]\teval-mlogloss:1.08959\n",
      "[11]\teval-mlogloss:1.08875\n",
      "[12]\teval-mlogloss:1.08793\n",
      "[13]\teval-mlogloss:1.08714\n",
      "[14]\teval-mlogloss:1.08632\n",
      "[15]\teval-mlogloss:1.08554\n",
      "[16]\teval-mlogloss:1.08473\n",
      "[17]\teval-mlogloss:1.08393\n",
      "[18]\teval-mlogloss:1.08306\n",
      "[19]\teval-mlogloss:1.08228\n",
      "[20]\teval-mlogloss:1.08147\n",
      "[21]\teval-mlogloss:1.08066\n",
      "[22]\teval-mlogloss:1.07979\n",
      "[23]\teval-mlogloss:1.07901\n",
      "[24]\teval-mlogloss:1.07822\n",
      "[25]\teval-mlogloss:1.07742\n",
      "[26]\teval-mlogloss:1.07663\n",
      "[27]\teval-mlogloss:1.0758\n",
      "[28]\teval-mlogloss:1.07497\n",
      "[29]\teval-mlogloss:1.0742\n",
      "[30]\teval-mlogloss:1.07338\n",
      "[31]\teval-mlogloss:1.07251\n",
      "[32]\teval-mlogloss:1.07173\n",
      "[33]\teval-mlogloss:1.07089\n",
      "[34]\teval-mlogloss:1.07008\n",
      "[35]\teval-mlogloss:1.06925\n",
      "[36]\teval-mlogloss:1.06847\n",
      "[37]\teval-mlogloss:1.06769\n",
      "[38]\teval-mlogloss:1.06691\n",
      "[39]\teval-mlogloss:1.06611\n",
      "[40]\teval-mlogloss:1.0653\n",
      "[41]\teval-mlogloss:1.06451\n",
      "[42]\teval-mlogloss:1.06377\n",
      "[43]\teval-mlogloss:1.06298\n",
      "[44]\teval-mlogloss:1.06224\n",
      "[45]\teval-mlogloss:1.06143\n",
      "[46]\teval-mlogloss:1.06062\n",
      "[47]\teval-mlogloss:1.05981\n",
      "[48]\teval-mlogloss:1.05905\n",
      "[49]\teval-mlogloss:1.05827\n",
      "[50]\teval-mlogloss:1.05749\n",
      "[51]\teval-mlogloss:1.05671\n",
      "[52]\teval-mlogloss:1.05597\n",
      "[53]\teval-mlogloss:1.05521\n",
      "[54]\teval-mlogloss:1.05442\n",
      "[55]\teval-mlogloss:1.05361\n",
      "[56]\teval-mlogloss:1.05282\n",
      "[57]\teval-mlogloss:1.05204\n",
      "[58]\teval-mlogloss:1.05123\n",
      "[59]\teval-mlogloss:1.05042\n",
      "[60]\teval-mlogloss:1.04962\n",
      "[61]\teval-mlogloss:1.0489\n",
      "[62]\teval-mlogloss:1.04812\n",
      "[63]\teval-mlogloss:1.04737\n",
      "[64]\teval-mlogloss:1.04662\n",
      "[65]\teval-mlogloss:1.04582\n",
      "[66]\teval-mlogloss:1.04504\n",
      "[67]\teval-mlogloss:1.04429\n",
      "[68]\teval-mlogloss:1.04353\n",
      "[69]\teval-mlogloss:1.04282\n",
      "[70]\teval-mlogloss:1.04208\n",
      "[71]\teval-mlogloss:1.04137\n",
      "[72]\teval-mlogloss:1.04058\n",
      "[73]\teval-mlogloss:1.03984\n",
      "[74]\teval-mlogloss:1.0391\n",
      "[75]\teval-mlogloss:1.03834\n",
      "[76]\teval-mlogloss:1.03761\n",
      "[77]\teval-mlogloss:1.03689\n",
      "[78]\teval-mlogloss:1.03615\n",
      "[79]\teval-mlogloss:1.0354\n",
      "[80]\teval-mlogloss:1.03467\n",
      "[81]\teval-mlogloss:1.03394\n",
      "[82]\teval-mlogloss:1.03322\n",
      "[83]\teval-mlogloss:1.03251\n",
      "[84]\teval-mlogloss:1.03174\n",
      "[85]\teval-mlogloss:1.03097\n",
      "[86]\teval-mlogloss:1.03022\n",
      "[87]\teval-mlogloss:1.02947\n",
      "[88]\teval-mlogloss:1.0287\n",
      "[89]\teval-mlogloss:1.02795\n",
      "[90]\teval-mlogloss:1.02725\n",
      "[91]\teval-mlogloss:1.02651\n",
      "[92]\teval-mlogloss:1.02576\n",
      "[93]\teval-mlogloss:1.02505\n",
      "[94]\teval-mlogloss:1.02431\n",
      "[95]\teval-mlogloss:1.02358\n",
      "[96]\teval-mlogloss:1.02282\n",
      "[97]\teval-mlogloss:1.02209\n",
      "[98]\teval-mlogloss:1.02138\n",
      "[99]\teval-mlogloss:1.02067\n",
      "[100]\teval-mlogloss:1.01999\n",
      "[101]\teval-mlogloss:1.01925\n",
      "[102]\teval-mlogloss:1.01853\n",
      "[103]\teval-mlogloss:1.01785\n",
      "[104]\teval-mlogloss:1.0171\n",
      "[105]\teval-mlogloss:1.01639\n",
      "[106]\teval-mlogloss:1.01568\n",
      "[107]\teval-mlogloss:1.01501\n",
      "[108]\teval-mlogloss:1.01426\n",
      "[109]\teval-mlogloss:1.01352\n",
      "[110]\teval-mlogloss:1.0128\n",
      "[111]\teval-mlogloss:1.01209\n",
      "[112]\teval-mlogloss:1.01132\n",
      "[113]\teval-mlogloss:1.01061\n",
      "[114]\teval-mlogloss:1.0099\n",
      "[115]\teval-mlogloss:1.0092\n",
      "[116]\teval-mlogloss:1.00845\n",
      "[117]\teval-mlogloss:1.00776\n",
      "[118]\teval-mlogloss:1.00703\n",
      "[119]\teval-mlogloss:1.00631\n",
      "[120]\teval-mlogloss:1.00559\n",
      "[121]\teval-mlogloss:1.00486\n",
      "[122]\teval-mlogloss:1.00416\n",
      "[123]\teval-mlogloss:1.00344\n",
      "[124]\teval-mlogloss:1.00277\n",
      "[125]\teval-mlogloss:1.00205\n",
      "[126]\teval-mlogloss:1.00137\n",
      "[127]\teval-mlogloss:1.00071\n",
      "[128]\teval-mlogloss:0.999986\n",
      "[129]\teval-mlogloss:0.999312\n",
      "[130]\teval-mlogloss:0.998609\n",
      "[131]\teval-mlogloss:0.997905\n",
      "[132]\teval-mlogloss:0.99721\n",
      "[133]\teval-mlogloss:0.996521\n",
      "[134]\teval-mlogloss:0.99585\n",
      "[135]\teval-mlogloss:0.995129\n",
      "[136]\teval-mlogloss:0.994434\n",
      "[137]\teval-mlogloss:0.993716\n",
      "[138]\teval-mlogloss:0.993045\n",
      "[139]\teval-mlogloss:0.992402\n",
      "[140]\teval-mlogloss:0.991728\n",
      "[141]\teval-mlogloss:0.991109\n",
      "[142]\teval-mlogloss:0.990434\n",
      "[143]\teval-mlogloss:0.989753\n",
      "[144]\teval-mlogloss:0.989104\n",
      "[145]\teval-mlogloss:0.988446\n",
      "[146]\teval-mlogloss:0.987775\n",
      "[147]\teval-mlogloss:0.987034\n",
      "[148]\teval-mlogloss:0.986318\n",
      "[149]\teval-mlogloss:0.985603\n",
      "[150]\teval-mlogloss:0.984896\n",
      "[151]\teval-mlogloss:0.984221\n",
      "[152]\teval-mlogloss:0.983555\n",
      "[153]\teval-mlogloss:0.982837\n",
      "[154]\teval-mlogloss:0.982152\n",
      "[155]\teval-mlogloss:0.981476\n",
      "[156]\teval-mlogloss:0.980817\n",
      "[157]\teval-mlogloss:0.98014\n",
      "[158]\teval-mlogloss:0.979463\n",
      "[159]\teval-mlogloss:0.978798\n",
      "[160]\teval-mlogloss:0.978132\n",
      "[161]\teval-mlogloss:0.977411\n",
      "[162]\teval-mlogloss:0.976734\n",
      "[163]\teval-mlogloss:0.976046\n",
      "[164]\teval-mlogloss:0.975388\n",
      "[165]\teval-mlogloss:0.974732\n",
      "[166]\teval-mlogloss:0.974084\n",
      "[167]\teval-mlogloss:0.973389\n",
      "[168]\teval-mlogloss:0.972732\n",
      "[169]\teval-mlogloss:0.9721\n",
      "[170]\teval-mlogloss:0.971454\n",
      "[171]\teval-mlogloss:0.970761\n",
      "[172]\teval-mlogloss:0.970117\n",
      "[173]\teval-mlogloss:0.969498\n",
      "[174]\teval-mlogloss:0.968851\n",
      "[175]\teval-mlogloss:0.968205\n",
      "[176]\teval-mlogloss:0.967562\n",
      "[177]\teval-mlogloss:0.966914\n",
      "[178]\teval-mlogloss:0.966244\n",
      "[179]\teval-mlogloss:0.965606\n",
      "[180]\teval-mlogloss:0.964961\n",
      "[181]\teval-mlogloss:0.964324\n",
      "[182]\teval-mlogloss:0.963669\n",
      "[183]\teval-mlogloss:0.963007\n",
      "[184]\teval-mlogloss:0.962333\n",
      "[185]\teval-mlogloss:0.961704\n",
      "[186]\teval-mlogloss:0.961078\n",
      "[187]\teval-mlogloss:0.960402\n",
      "[188]\teval-mlogloss:0.95974\n",
      "[189]\teval-mlogloss:0.959117\n",
      "[190]\teval-mlogloss:0.958465\n",
      "[191]\teval-mlogloss:0.957787\n",
      "[192]\teval-mlogloss:0.957184\n",
      "[193]\teval-mlogloss:0.956542\n",
      "[194]\teval-mlogloss:0.955876\n",
      "[195]\teval-mlogloss:0.955271\n",
      "[196]\teval-mlogloss:0.954623\n",
      "[197]\teval-mlogloss:0.953951\n",
      "[198]\teval-mlogloss:0.953344\n",
      "[199]\teval-mlogloss:0.952695\n",
      "[200]\teval-mlogloss:0.95208\n",
      "[201]\teval-mlogloss:0.951451\n",
      "[202]\teval-mlogloss:0.950831\n",
      "[203]\teval-mlogloss:0.950192\n",
      "[204]\teval-mlogloss:0.949595\n",
      "[205]\teval-mlogloss:0.948991\n",
      "[206]\teval-mlogloss:0.948379\n",
      "[207]\teval-mlogloss:0.947757\n",
      "[208]\teval-mlogloss:0.947084\n",
      "[209]\teval-mlogloss:0.946439\n",
      "[210]\teval-mlogloss:0.94582\n",
      "[211]\teval-mlogloss:0.945168\n",
      "[212]\teval-mlogloss:0.944472\n",
      "[213]\teval-mlogloss:0.94386\n",
      "[214]\teval-mlogloss:0.943247\n",
      "[215]\teval-mlogloss:0.94266\n",
      "[216]\teval-mlogloss:0.942022\n",
      "[217]\teval-mlogloss:0.941424\n",
      "[218]\teval-mlogloss:0.940794\n",
      "[219]\teval-mlogloss:0.940134\n",
      "[220]\teval-mlogloss:0.939519\n",
      "[221]\teval-mlogloss:0.938879\n",
      "[222]\teval-mlogloss:0.938225\n",
      "[223]\teval-mlogloss:0.937627\n",
      "[224]\teval-mlogloss:0.936974\n",
      "[225]\teval-mlogloss:0.936401\n",
      "[226]\teval-mlogloss:0.935802\n",
      "[227]\teval-mlogloss:0.935206\n",
      "[228]\teval-mlogloss:0.934594\n",
      "[229]\teval-mlogloss:0.934001\n",
      "[230]\teval-mlogloss:0.933351\n",
      "[231]\teval-mlogloss:0.93274\n",
      "[232]\teval-mlogloss:0.932097\n",
      "[233]\teval-mlogloss:0.93149\n",
      "[234]\teval-mlogloss:0.930875\n",
      "[235]\teval-mlogloss:0.930227\n",
      "[236]\teval-mlogloss:0.929639\n",
      "[237]\teval-mlogloss:0.929013\n",
      "[238]\teval-mlogloss:0.928397\n",
      "[239]\teval-mlogloss:0.927792\n",
      "[240]\teval-mlogloss:0.92723\n",
      "[241]\teval-mlogloss:0.926596\n",
      "[242]\teval-mlogloss:0.925978\n",
      "[243]\teval-mlogloss:0.925369\n",
      "[244]\teval-mlogloss:0.92479\n",
      "[245]\teval-mlogloss:0.924152\n",
      "[246]\teval-mlogloss:0.923518\n",
      "[247]\teval-mlogloss:0.922884\n",
      "[248]\teval-mlogloss:0.922311\n",
      "[249]\teval-mlogloss:0.921729\n",
      "[250]\teval-mlogloss:0.921132\n",
      "[251]\teval-mlogloss:0.920538\n",
      "[252]\teval-mlogloss:0.919945\n",
      "[253]\teval-mlogloss:0.919361\n",
      "[254]\teval-mlogloss:0.918778\n",
      "[255]\teval-mlogloss:0.918205\n",
      "[256]\teval-mlogloss:0.91758\n",
      "[257]\teval-mlogloss:0.916987\n",
      "[258]\teval-mlogloss:0.916384\n",
      "[259]\teval-mlogloss:0.915822\n",
      "[260]\teval-mlogloss:0.915212\n",
      "[261]\teval-mlogloss:0.914628\n",
      "[262]\teval-mlogloss:0.914012\n",
      "[263]\teval-mlogloss:0.913359\n",
      "[264]\teval-mlogloss:0.912741\n",
      "[265]\teval-mlogloss:0.91218\n",
      "[266]\teval-mlogloss:0.911616\n",
      "[267]\teval-mlogloss:0.911046\n",
      "[268]\teval-mlogloss:0.910462\n",
      "[269]\teval-mlogloss:0.909828\n",
      "[270]\teval-mlogloss:0.909253\n",
      "[271]\teval-mlogloss:0.908675\n",
      "[272]\teval-mlogloss:0.908064\n",
      "[273]\teval-mlogloss:0.907465\n",
      "[274]\teval-mlogloss:0.906897\n",
      "[275]\teval-mlogloss:0.906329\n",
      "[276]\teval-mlogloss:0.905709\n",
      "[277]\teval-mlogloss:0.905142\n",
      "[278]\teval-mlogloss:0.904549\n",
      "[279]\teval-mlogloss:0.903961\n",
      "[280]\teval-mlogloss:0.903359\n",
      "[281]\teval-mlogloss:0.902763\n",
      "[282]\teval-mlogloss:0.902211\n",
      "[283]\teval-mlogloss:0.901616\n",
      "[284]\teval-mlogloss:0.901006\n",
      "[285]\teval-mlogloss:0.900439\n",
      "[286]\teval-mlogloss:0.899887\n",
      "[287]\teval-mlogloss:0.89932\n",
      "[288]\teval-mlogloss:0.898743\n",
      "[289]\teval-mlogloss:0.898125\n",
      "[290]\teval-mlogloss:0.897523\n",
      "[291]\teval-mlogloss:0.896947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[292]\teval-mlogloss:0.896326\n",
      "[293]\teval-mlogloss:0.895763\n",
      "[294]\teval-mlogloss:0.895179\n",
      "[295]\teval-mlogloss:0.89464\n",
      "[296]\teval-mlogloss:0.894067\n",
      "[297]\teval-mlogloss:0.893538\n",
      "[298]\teval-mlogloss:0.892998\n",
      "[299]\teval-mlogloss:0.892478\n",
      "[300]\teval-mlogloss:0.891903\n",
      "[301]\teval-mlogloss:0.891343\n",
      "[302]\teval-mlogloss:0.890778\n",
      "[303]\teval-mlogloss:0.890209\n",
      "[304]\teval-mlogloss:0.889658\n",
      "[305]\teval-mlogloss:0.889098\n",
      "[306]\teval-mlogloss:0.888539\n",
      "[307]\teval-mlogloss:0.887962\n",
      "[308]\teval-mlogloss:0.887408\n",
      "[309]\teval-mlogloss:0.886853\n",
      "[310]\teval-mlogloss:0.8863\n",
      "[311]\teval-mlogloss:0.885738\n",
      "[312]\teval-mlogloss:0.88519\n",
      "[313]\teval-mlogloss:0.884642\n",
      "[314]\teval-mlogloss:0.884076\n",
      "[315]\teval-mlogloss:0.883517\n",
      "[316]\teval-mlogloss:0.882966\n",
      "[317]\teval-mlogloss:0.882426\n",
      "[318]\teval-mlogloss:0.881838\n",
      "[319]\teval-mlogloss:0.881286\n",
      "[320]\teval-mlogloss:0.880766\n",
      "[321]\teval-mlogloss:0.880219\n",
      "[322]\teval-mlogloss:0.879651\n",
      "[323]\teval-mlogloss:0.879061\n",
      "[324]\teval-mlogloss:0.878506\n",
      "[325]\teval-mlogloss:0.877926\n",
      "[326]\teval-mlogloss:0.877375\n",
      "[327]\teval-mlogloss:0.876822\n",
      "[328]\teval-mlogloss:0.876275\n",
      "[329]\teval-mlogloss:0.875726\n",
      "[330]\teval-mlogloss:0.875185\n",
      "[331]\teval-mlogloss:0.874634\n",
      "[332]\teval-mlogloss:0.874042\n",
      "[333]\teval-mlogloss:0.873521\n",
      "[334]\teval-mlogloss:0.872963\n",
      "[335]\teval-mlogloss:0.872405\n",
      "[336]\teval-mlogloss:0.871847\n",
      "[337]\teval-mlogloss:0.87132\n",
      "[338]\teval-mlogloss:0.870754\n",
      "[339]\teval-mlogloss:0.870224\n",
      "[340]\teval-mlogloss:0.869735\n",
      "[341]\teval-mlogloss:0.869217\n",
      "[342]\teval-mlogloss:0.868655\n",
      "[343]\teval-mlogloss:0.868111\n",
      "[344]\teval-mlogloss:0.867617\n",
      "[345]\teval-mlogloss:0.867083\n",
      "[346]\teval-mlogloss:0.866553\n",
      "[347]\teval-mlogloss:0.866047\n",
      "[348]\teval-mlogloss:0.865512\n",
      "[349]\teval-mlogloss:0.864951\n",
      "[350]\teval-mlogloss:0.86445\n",
      "[351]\teval-mlogloss:0.863938\n",
      "[352]\teval-mlogloss:0.863393\n",
      "[353]\teval-mlogloss:0.862809\n",
      "[354]\teval-mlogloss:0.86226\n",
      "[355]\teval-mlogloss:0.861729\n",
      "[356]\teval-mlogloss:0.861167\n",
      "[357]\teval-mlogloss:0.86063\n",
      "[358]\teval-mlogloss:0.860109\n",
      "[359]\teval-mlogloss:0.859555\n",
      "[360]\teval-mlogloss:0.859006\n",
      "[361]\teval-mlogloss:0.858488\n",
      "[362]\teval-mlogloss:0.857974\n",
      "[363]\teval-mlogloss:0.857474\n",
      "[364]\teval-mlogloss:0.856984\n",
      "[365]\teval-mlogloss:0.856456\n",
      "[366]\teval-mlogloss:0.855934\n",
      "[367]\teval-mlogloss:0.85542\n",
      "[368]\teval-mlogloss:0.854906\n",
      "[369]\teval-mlogloss:0.854379\n",
      "[370]\teval-mlogloss:0.853837\n",
      "[371]\teval-mlogloss:0.853318\n",
      "[372]\teval-mlogloss:0.852777\n",
      "[373]\teval-mlogloss:0.852277\n",
      "[374]\teval-mlogloss:0.851764\n",
      "[375]\teval-mlogloss:0.851277\n",
      "[376]\teval-mlogloss:0.85077\n",
      "[377]\teval-mlogloss:0.850232\n",
      "[378]\teval-mlogloss:0.849707\n",
      "[379]\teval-mlogloss:0.849159\n",
      "[380]\teval-mlogloss:0.848655\n",
      "[381]\teval-mlogloss:0.848127\n",
      "[382]\teval-mlogloss:0.847625\n",
      "[383]\teval-mlogloss:0.847141\n",
      "[384]\teval-mlogloss:0.846657\n",
      "[385]\teval-mlogloss:0.846155\n",
      "[386]\teval-mlogloss:0.845662\n",
      "[387]\teval-mlogloss:0.84517\n",
      "[388]\teval-mlogloss:0.844659\n",
      "[389]\teval-mlogloss:0.844146\n",
      "[390]\teval-mlogloss:0.843635\n",
      "[391]\teval-mlogloss:0.843093\n",
      "[392]\teval-mlogloss:0.842567\n",
      "[393]\teval-mlogloss:0.842036\n",
      "[394]\teval-mlogloss:0.84151\n",
      "[395]\teval-mlogloss:0.840991\n",
      "[396]\teval-mlogloss:0.840447\n",
      "[397]\teval-mlogloss:0.839917\n",
      "[398]\teval-mlogloss:0.839432\n",
      "[399]\teval-mlogloss:0.838911\n",
      "[400]\teval-mlogloss:0.838422\n",
      "[401]\teval-mlogloss:0.837921\n",
      "[402]\teval-mlogloss:0.837408\n",
      "[403]\teval-mlogloss:0.836911\n",
      "[404]\teval-mlogloss:0.836404\n",
      "[405]\teval-mlogloss:0.835918\n",
      "[406]\teval-mlogloss:0.835425\n",
      "[407]\teval-mlogloss:0.834941\n",
      "[408]\teval-mlogloss:0.834451\n",
      "[409]\teval-mlogloss:0.833954\n",
      "[410]\teval-mlogloss:0.833454\n",
      "[411]\teval-mlogloss:0.832965\n",
      "[412]\teval-mlogloss:0.832441\n",
      "[413]\teval-mlogloss:0.83199\n",
      "[414]\teval-mlogloss:0.831461\n",
      "[415]\teval-mlogloss:0.830943\n",
      "[416]\teval-mlogloss:0.830434\n",
      "[417]\teval-mlogloss:0.829906\n",
      "[418]\teval-mlogloss:0.829391\n",
      "[419]\teval-mlogloss:0.828875\n",
      "[420]\teval-mlogloss:0.828366\n",
      "[421]\teval-mlogloss:0.827899\n",
      "[422]\teval-mlogloss:0.827367\n",
      "[423]\teval-mlogloss:0.826887\n",
      "[424]\teval-mlogloss:0.826409\n",
      "[425]\teval-mlogloss:0.825915\n",
      "[426]\teval-mlogloss:0.825431\n",
      "[427]\teval-mlogloss:0.824929\n",
      "[428]\teval-mlogloss:0.824439\n",
      "[429]\teval-mlogloss:0.823916\n",
      "[430]\teval-mlogloss:0.823419\n",
      "[431]\teval-mlogloss:0.822956\n",
      "[432]\teval-mlogloss:0.822508\n",
      "[433]\teval-mlogloss:0.822014\n",
      "[434]\teval-mlogloss:0.821554\n",
      "[435]\teval-mlogloss:0.821115\n",
      "[436]\teval-mlogloss:0.820635\n",
      "[437]\teval-mlogloss:0.82017\n",
      "[438]\teval-mlogloss:0.819697\n",
      "[439]\teval-mlogloss:0.819145\n",
      "[440]\teval-mlogloss:0.818662\n",
      "[441]\teval-mlogloss:0.818203\n",
      "[442]\teval-mlogloss:0.817743\n",
      "[443]\teval-mlogloss:0.8173\n",
      "[444]\teval-mlogloss:0.816819\n",
      "[445]\teval-mlogloss:0.816358\n",
      "[446]\teval-mlogloss:0.815904\n",
      "[447]\teval-mlogloss:0.815437\n",
      "[448]\teval-mlogloss:0.814982\n",
      "[449]\teval-mlogloss:0.814512\n",
      "[450]\teval-mlogloss:0.814054\n",
      "[451]\teval-mlogloss:0.813594\n",
      "[452]\teval-mlogloss:0.813083\n",
      "[453]\teval-mlogloss:0.812578\n",
      "[454]\teval-mlogloss:0.812064\n",
      "[455]\teval-mlogloss:0.811556\n",
      "[456]\teval-mlogloss:0.8111\n",
      "[457]\teval-mlogloss:0.810617\n",
      "[458]\teval-mlogloss:0.810161\n",
      "[459]\teval-mlogloss:0.809678\n",
      "[460]\teval-mlogloss:0.809189\n",
      "[461]\teval-mlogloss:0.808721\n",
      "[462]\teval-mlogloss:0.808255\n",
      "[463]\teval-mlogloss:0.807762\n",
      "[464]\teval-mlogloss:0.807279\n",
      "[465]\teval-mlogloss:0.806796\n",
      "[466]\teval-mlogloss:0.806347\n",
      "[467]\teval-mlogloss:0.805867\n",
      "[468]\teval-mlogloss:0.805429\n",
      "[469]\teval-mlogloss:0.804953\n",
      "[470]\teval-mlogloss:0.804498\n",
      "[471]\teval-mlogloss:0.804024\n",
      "[472]\teval-mlogloss:0.803547\n",
      "[473]\teval-mlogloss:0.803073\n",
      "[474]\teval-mlogloss:0.802614\n",
      "[475]\teval-mlogloss:0.802177\n",
      "[476]\teval-mlogloss:0.80174\n",
      "[477]\teval-mlogloss:0.801297\n",
      "[478]\teval-mlogloss:0.800858\n",
      "[479]\teval-mlogloss:0.800389\n",
      "[480]\teval-mlogloss:0.799944\n",
      "[481]\teval-mlogloss:0.799499\n",
      "[482]\teval-mlogloss:0.799045\n",
      "[483]\teval-mlogloss:0.798574\n",
      "[484]\teval-mlogloss:0.798109\n",
      "[485]\teval-mlogloss:0.797637\n",
      "[486]\teval-mlogloss:0.797197\n",
      "[487]\teval-mlogloss:0.796738\n",
      "[488]\teval-mlogloss:0.796286\n",
      "[489]\teval-mlogloss:0.795848\n",
      "[490]\teval-mlogloss:0.795408\n",
      "[491]\teval-mlogloss:0.794947\n",
      "[492]\teval-mlogloss:0.794511\n",
      "[493]\teval-mlogloss:0.79404\n",
      "[494]\teval-mlogloss:0.793584\n",
      "[495]\teval-mlogloss:0.79316\n",
      "[496]\teval-mlogloss:0.792686\n",
      "[497]\teval-mlogloss:0.792237\n",
      "[498]\teval-mlogloss:0.791785\n",
      "[499]\teval-mlogloss:0.791337\n",
      "[500]\teval-mlogloss:0.790867\n",
      "[501]\teval-mlogloss:0.790412\n",
      "[502]\teval-mlogloss:0.789994\n",
      "[503]\teval-mlogloss:0.789535\n",
      "[504]\teval-mlogloss:0.789073\n",
      "[505]\teval-mlogloss:0.788622\n",
      "[506]\teval-mlogloss:0.788163\n",
      "[507]\teval-mlogloss:0.787734\n",
      "[508]\teval-mlogloss:0.787292\n",
      "[509]\teval-mlogloss:0.786852\n",
      "[510]\teval-mlogloss:0.786421\n",
      "[511]\teval-mlogloss:0.785986\n",
      "[512]\teval-mlogloss:0.785555\n",
      "[513]\teval-mlogloss:0.785101\n",
      "[514]\teval-mlogloss:0.784652\n",
      "[515]\teval-mlogloss:0.784202\n",
      "[516]\teval-mlogloss:0.783747\n",
      "[517]\teval-mlogloss:0.783317\n",
      "[518]\teval-mlogloss:0.782856\n",
      "[519]\teval-mlogloss:0.782404\n",
      "[520]\teval-mlogloss:0.781946\n",
      "[521]\teval-mlogloss:0.781521\n",
      "[522]\teval-mlogloss:0.781048\n",
      "[523]\teval-mlogloss:0.780623\n",
      "[524]\teval-mlogloss:0.780123\n",
      "[525]\teval-mlogloss:0.779634\n",
      "[526]\teval-mlogloss:0.779187\n",
      "[527]\teval-mlogloss:0.778769\n",
      "[528]\teval-mlogloss:0.778315\n",
      "[529]\teval-mlogloss:0.7779\n",
      "[530]\teval-mlogloss:0.777451\n",
      "[531]\teval-mlogloss:0.777008\n",
      "[532]\teval-mlogloss:0.776586\n",
      "[533]\teval-mlogloss:0.776136\n",
      "[534]\teval-mlogloss:0.775657\n",
      "[535]\teval-mlogloss:0.775231\n",
      "[536]\teval-mlogloss:0.774799\n",
      "[537]\teval-mlogloss:0.774375\n",
      "[538]\teval-mlogloss:0.773948\n",
      "[539]\teval-mlogloss:0.773504\n",
      "[540]\teval-mlogloss:0.773064\n",
      "[541]\teval-mlogloss:0.772672\n",
      "[542]\teval-mlogloss:0.772228\n",
      "[543]\teval-mlogloss:0.771794\n",
      "[544]\teval-mlogloss:0.771377\n",
      "[545]\teval-mlogloss:0.770925\n",
      "[546]\teval-mlogloss:0.7705\n",
      "[547]\teval-mlogloss:0.770029\n",
      "[548]\teval-mlogloss:0.769607\n",
      "[549]\teval-mlogloss:0.769175\n",
      "[550]\teval-mlogloss:0.768756\n",
      "[551]\teval-mlogloss:0.768319\n",
      "[552]\teval-mlogloss:0.767885\n",
      "[553]\teval-mlogloss:0.767469\n",
      "[554]\teval-mlogloss:0.767058\n",
      "[555]\teval-mlogloss:0.766655\n",
      "[556]\teval-mlogloss:0.766242\n",
      "[557]\teval-mlogloss:0.765782\n",
      "[558]\teval-mlogloss:0.765353\n",
      "[559]\teval-mlogloss:0.764897\n",
      "[560]\teval-mlogloss:0.764456\n",
      "[561]\teval-mlogloss:0.764008\n",
      "[562]\teval-mlogloss:0.763578\n",
      "[563]\teval-mlogloss:0.763133\n",
      "[564]\teval-mlogloss:0.76273\n",
      "[565]\teval-mlogloss:0.762287\n",
      "[566]\teval-mlogloss:0.761883\n",
      "[567]\teval-mlogloss:0.761481\n",
      "[568]\teval-mlogloss:0.76105\n",
      "[569]\teval-mlogloss:0.760639\n",
      "[570]\teval-mlogloss:0.760249\n",
      "[571]\teval-mlogloss:0.759803\n",
      "[572]\teval-mlogloss:0.759379\n",
      "[573]\teval-mlogloss:0.758929\n",
      "[574]\teval-mlogloss:0.758473\n",
      "[575]\teval-mlogloss:0.758051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[576]\teval-mlogloss:0.757639\n",
      "[577]\teval-mlogloss:0.757224\n",
      "[578]\teval-mlogloss:0.75679\n",
      "[579]\teval-mlogloss:0.75639\n",
      "[580]\teval-mlogloss:0.75595\n",
      "[581]\teval-mlogloss:0.755537\n",
      "[582]\teval-mlogloss:0.755116\n",
      "[583]\teval-mlogloss:0.754732\n",
      "[584]\teval-mlogloss:0.754349\n",
      "[585]\teval-mlogloss:0.753946\n",
      "[586]\teval-mlogloss:0.753505\n",
      "[587]\teval-mlogloss:0.753123\n",
      "[588]\teval-mlogloss:0.752707\n",
      "[589]\teval-mlogloss:0.752283\n",
      "[590]\teval-mlogloss:0.751893\n",
      "[591]\teval-mlogloss:0.751479\n",
      "[592]\teval-mlogloss:0.751064\n",
      "[593]\teval-mlogloss:0.750622\n",
      "[594]\teval-mlogloss:0.750212\n",
      "[595]\teval-mlogloss:0.749808\n",
      "[596]\teval-mlogloss:0.749403\n",
      "[597]\teval-mlogloss:0.749005\n",
      "[598]\teval-mlogloss:0.748621\n",
      "[599]\teval-mlogloss:0.748176\n",
      "[600]\teval-mlogloss:0.747767\n",
      "[601]\teval-mlogloss:0.74734\n",
      "[602]\teval-mlogloss:0.746913\n",
      "[603]\teval-mlogloss:0.746514\n",
      "[604]\teval-mlogloss:0.746081\n",
      "[605]\teval-mlogloss:0.745632\n",
      "[606]\teval-mlogloss:0.74521\n",
      "[607]\teval-mlogloss:0.74484\n",
      "[608]\teval-mlogloss:0.744435\n",
      "[609]\teval-mlogloss:0.74401\n",
      "[610]\teval-mlogloss:0.743572\n",
      "[611]\teval-mlogloss:0.74318\n",
      "[612]\teval-mlogloss:0.742775\n",
      "[613]\teval-mlogloss:0.742382\n",
      "[614]\teval-mlogloss:0.741985\n",
      "[615]\teval-mlogloss:0.741585\n",
      "[616]\teval-mlogloss:0.741169\n",
      "[617]\teval-mlogloss:0.740763\n",
      "[618]\teval-mlogloss:0.740375\n",
      "[619]\teval-mlogloss:0.739982\n",
      "[620]\teval-mlogloss:0.739557\n",
      "[621]\teval-mlogloss:0.739174\n",
      "[622]\teval-mlogloss:0.738753\n",
      "[623]\teval-mlogloss:0.738337\n",
      "[624]\teval-mlogloss:0.73793\n",
      "[625]\teval-mlogloss:0.737533\n",
      "[626]\teval-mlogloss:0.737116\n",
      "[627]\teval-mlogloss:0.736723\n",
      "[628]\teval-mlogloss:0.736351\n",
      "[629]\teval-mlogloss:0.735921\n",
      "[630]\teval-mlogloss:0.735538\n",
      "[631]\teval-mlogloss:0.735148\n",
      "[632]\teval-mlogloss:0.734766\n",
      "[633]\teval-mlogloss:0.734415\n",
      "[634]\teval-mlogloss:0.734016\n",
      "[635]\teval-mlogloss:0.733658\n",
      "[636]\teval-mlogloss:0.73327\n",
      "[637]\teval-mlogloss:0.732887\n",
      "[638]\teval-mlogloss:0.732494\n",
      "[639]\teval-mlogloss:0.732093\n",
      "[640]\teval-mlogloss:0.731695\n",
      "[641]\teval-mlogloss:0.731284\n",
      "[642]\teval-mlogloss:0.730861\n",
      "[643]\teval-mlogloss:0.730488\n",
      "[644]\teval-mlogloss:0.73008\n",
      "[645]\teval-mlogloss:0.7297\n",
      "[646]\teval-mlogloss:0.729292\n",
      "[647]\teval-mlogloss:0.728862\n",
      "[648]\teval-mlogloss:0.728478\n",
      "[649]\teval-mlogloss:0.728096\n",
      "[650]\teval-mlogloss:0.727722\n",
      "[651]\teval-mlogloss:0.727358\n",
      "[652]\teval-mlogloss:0.726947\n",
      "[653]\teval-mlogloss:0.726582\n",
      "[654]\teval-mlogloss:0.726167\n",
      "[655]\teval-mlogloss:0.725801\n",
      "[656]\teval-mlogloss:0.72543\n",
      "[657]\teval-mlogloss:0.725051\n",
      "[658]\teval-mlogloss:0.72467\n",
      "[659]\teval-mlogloss:0.724283\n",
      "[660]\teval-mlogloss:0.723889\n",
      "[661]\teval-mlogloss:0.723517\n",
      "[662]\teval-mlogloss:0.723138\n",
      "[663]\teval-mlogloss:0.722721\n",
      "[664]\teval-mlogloss:0.72235\n",
      "[665]\teval-mlogloss:0.721961\n",
      "[666]\teval-mlogloss:0.721561\n",
      "[667]\teval-mlogloss:0.72121\n",
      "[668]\teval-mlogloss:0.720843\n",
      "[669]\teval-mlogloss:0.720458\n",
      "[670]\teval-mlogloss:0.720102\n",
      "[671]\teval-mlogloss:0.71972\n",
      "[672]\teval-mlogloss:0.719345\n",
      "[673]\teval-mlogloss:0.718936\n",
      "[674]\teval-mlogloss:0.718569\n",
      "[675]\teval-mlogloss:0.718196\n",
      "[676]\teval-mlogloss:0.717823\n",
      "[677]\teval-mlogloss:0.717431\n",
      "[678]\teval-mlogloss:0.717074\n",
      "[679]\teval-mlogloss:0.716694\n",
      "[680]\teval-mlogloss:0.716307\n",
      "[681]\teval-mlogloss:0.715917\n",
      "[682]\teval-mlogloss:0.715556\n",
      "[683]\teval-mlogloss:0.715161\n",
      "[684]\teval-mlogloss:0.714804\n",
      "[685]\teval-mlogloss:0.714395\n",
      "[686]\teval-mlogloss:0.714024\n",
      "[687]\teval-mlogloss:0.71364\n",
      "[688]\teval-mlogloss:0.713249\n",
      "[689]\teval-mlogloss:0.712901\n",
      "[690]\teval-mlogloss:0.712545\n",
      "[691]\teval-mlogloss:0.712197\n",
      "[692]\teval-mlogloss:0.71184\n",
      "[693]\teval-mlogloss:0.711473\n",
      "[694]\teval-mlogloss:0.711097\n",
      "[695]\teval-mlogloss:0.710691\n",
      "[696]\teval-mlogloss:0.7103\n",
      "[697]\teval-mlogloss:0.709898\n",
      "[698]\teval-mlogloss:0.70955\n",
      "[699]\teval-mlogloss:0.709179\n",
      "[700]\teval-mlogloss:0.708823\n",
      "[701]\teval-mlogloss:0.708431\n",
      "[702]\teval-mlogloss:0.7081\n",
      "[703]\teval-mlogloss:0.707745\n",
      "[704]\teval-mlogloss:0.707366\n",
      "[705]\teval-mlogloss:0.706968\n",
      "[706]\teval-mlogloss:0.706578\n",
      "[707]\teval-mlogloss:0.706213\n",
      "[708]\teval-mlogloss:0.705844\n",
      "[709]\teval-mlogloss:0.705456\n",
      "[710]\teval-mlogloss:0.705087\n",
      "[711]\teval-mlogloss:0.704695\n",
      "[712]\teval-mlogloss:0.70433\n",
      "[713]\teval-mlogloss:0.703943\n",
      "[714]\teval-mlogloss:0.703598\n",
      "[715]\teval-mlogloss:0.703228\n",
      "[716]\teval-mlogloss:0.702866\n",
      "[717]\teval-mlogloss:0.702525\n",
      "[718]\teval-mlogloss:0.702157\n",
      "[719]\teval-mlogloss:0.701805\n",
      "[720]\teval-mlogloss:0.701418\n",
      "[721]\teval-mlogloss:0.70107\n",
      "[722]\teval-mlogloss:0.700676\n",
      "[723]\teval-mlogloss:0.700329\n",
      "[724]\teval-mlogloss:0.699955\n",
      "[725]\teval-mlogloss:0.699588\n",
      "[726]\teval-mlogloss:0.699209\n",
      "[727]\teval-mlogloss:0.698849\n",
      "[728]\teval-mlogloss:0.698497\n",
      "[729]\teval-mlogloss:0.698134\n",
      "[730]\teval-mlogloss:0.697771\n",
      "[731]\teval-mlogloss:0.697414\n",
      "[732]\teval-mlogloss:0.697068\n",
      "[733]\teval-mlogloss:0.696728\n",
      "[734]\teval-mlogloss:0.696377\n",
      "[735]\teval-mlogloss:0.696022\n",
      "[736]\teval-mlogloss:0.69568\n",
      "[737]\teval-mlogloss:0.69532\n",
      "[738]\teval-mlogloss:0.694956\n",
      "[739]\teval-mlogloss:0.694569\n",
      "[740]\teval-mlogloss:0.694207\n",
      "[741]\teval-mlogloss:0.693851\n",
      "[742]\teval-mlogloss:0.693495\n",
      "[743]\teval-mlogloss:0.693124\n",
      "[744]\teval-mlogloss:0.692777\n",
      "[745]\teval-mlogloss:0.692394\n",
      "[746]\teval-mlogloss:0.692035\n",
      "[747]\teval-mlogloss:0.691666\n",
      "[748]\teval-mlogloss:0.691319\n",
      "[749]\teval-mlogloss:0.690926\n",
      "[750]\teval-mlogloss:0.690598\n",
      "[751]\teval-mlogloss:0.690254\n",
      "[752]\teval-mlogloss:0.689883\n",
      "[753]\teval-mlogloss:0.689532\n",
      "[754]\teval-mlogloss:0.689193\n",
      "[755]\teval-mlogloss:0.688827\n",
      "[756]\teval-mlogloss:0.688463\n",
      "[757]\teval-mlogloss:0.688126\n",
      "[758]\teval-mlogloss:0.687769\n",
      "[759]\teval-mlogloss:0.687419\n",
      "[760]\teval-mlogloss:0.687051\n",
      "[761]\teval-mlogloss:0.686688\n",
      "[762]\teval-mlogloss:0.686308\n",
      "[763]\teval-mlogloss:0.685966\n",
      "[764]\teval-mlogloss:0.685582\n",
      "[765]\teval-mlogloss:0.685232\n",
      "[766]\teval-mlogloss:0.684879\n",
      "[767]\teval-mlogloss:0.684544\n",
      "[768]\teval-mlogloss:0.684181\n",
      "[769]\teval-mlogloss:0.683807\n",
      "[770]\teval-mlogloss:0.683461\n",
      "[771]\teval-mlogloss:0.683063\n",
      "[772]\teval-mlogloss:0.682731\n",
      "[773]\teval-mlogloss:0.682396\n",
      "[774]\teval-mlogloss:0.682067\n",
      "[775]\teval-mlogloss:0.681718\n",
      "[776]\teval-mlogloss:0.681352\n",
      "[777]\teval-mlogloss:0.681008\n",
      "[778]\teval-mlogloss:0.680688\n",
      "[779]\teval-mlogloss:0.680363\n",
      "[780]\teval-mlogloss:0.680013\n",
      "[781]\teval-mlogloss:0.679664\n",
      "[782]\teval-mlogloss:0.67933\n",
      "[783]\teval-mlogloss:0.678989\n",
      "[784]\teval-mlogloss:0.678644\n",
      "[785]\teval-mlogloss:0.6783\n",
      "[786]\teval-mlogloss:0.677934\n",
      "[787]\teval-mlogloss:0.677599\n",
      "[788]\teval-mlogloss:0.677267\n",
      "[789]\teval-mlogloss:0.676923\n",
      "[790]\teval-mlogloss:0.676612\n",
      "[791]\teval-mlogloss:0.67625\n",
      "[792]\teval-mlogloss:0.675925\n",
      "[793]\teval-mlogloss:0.675615\n",
      "[794]\teval-mlogloss:0.675282\n",
      "[795]\teval-mlogloss:0.67492\n",
      "[796]\teval-mlogloss:0.67456\n",
      "[797]\teval-mlogloss:0.67424\n",
      "[798]\teval-mlogloss:0.673891\n",
      "[799]\teval-mlogloss:0.673529\n",
      "[800]\teval-mlogloss:0.673167\n",
      "[801]\teval-mlogloss:0.672807\n",
      "[802]\teval-mlogloss:0.672484\n",
      "[803]\teval-mlogloss:0.672164\n",
      "[804]\teval-mlogloss:0.671835\n",
      "[805]\teval-mlogloss:0.671485\n",
      "[806]\teval-mlogloss:0.671114\n",
      "[807]\teval-mlogloss:0.670801\n",
      "[808]\teval-mlogloss:0.670463\n",
      "[809]\teval-mlogloss:0.670111\n",
      "[810]\teval-mlogloss:0.669795\n",
      "[811]\teval-mlogloss:0.669469\n",
      "[812]\teval-mlogloss:0.669098\n",
      "[813]\teval-mlogloss:0.668783\n",
      "[814]\teval-mlogloss:0.668451\n",
      "[815]\teval-mlogloss:0.668118\n",
      "[816]\teval-mlogloss:0.667787\n",
      "[817]\teval-mlogloss:0.667481\n",
      "[818]\teval-mlogloss:0.66713\n",
      "[819]\teval-mlogloss:0.666811\n",
      "[820]\teval-mlogloss:0.666493\n",
      "[821]\teval-mlogloss:0.666175\n",
      "[822]\teval-mlogloss:0.665854\n",
      "[823]\teval-mlogloss:0.66551\n",
      "[824]\teval-mlogloss:0.665166\n",
      "[825]\teval-mlogloss:0.664817\n",
      "[826]\teval-mlogloss:0.664485\n",
      "[827]\teval-mlogloss:0.66412\n",
      "[828]\teval-mlogloss:0.663756\n",
      "[829]\teval-mlogloss:0.663413\n",
      "[830]\teval-mlogloss:0.663109\n",
      "[831]\teval-mlogloss:0.662769\n",
      "[832]\teval-mlogloss:0.662407\n",
      "[833]\teval-mlogloss:0.662095\n",
      "[834]\teval-mlogloss:0.661782\n",
      "[835]\teval-mlogloss:0.661454\n",
      "[836]\teval-mlogloss:0.661137\n",
      "[837]\teval-mlogloss:0.660804\n",
      "[838]\teval-mlogloss:0.660486\n",
      "[839]\teval-mlogloss:0.660157\n",
      "[840]\teval-mlogloss:0.659824\n",
      "[841]\teval-mlogloss:0.659479\n",
      "[842]\teval-mlogloss:0.659165\n",
      "[843]\teval-mlogloss:0.658824\n",
      "[844]\teval-mlogloss:0.658469\n",
      "[845]\teval-mlogloss:0.658162\n",
      "[846]\teval-mlogloss:0.657832\n",
      "[847]\teval-mlogloss:0.657525\n",
      "[848]\teval-mlogloss:0.657188\n",
      "[849]\teval-mlogloss:0.656855\n",
      "[850]\teval-mlogloss:0.656534\n",
      "[851]\teval-mlogloss:0.656222\n",
      "[852]\teval-mlogloss:0.655893\n",
      "[853]\teval-mlogloss:0.655595\n",
      "[854]\teval-mlogloss:0.655283\n",
      "[855]\teval-mlogloss:0.654949\n",
      "[856]\teval-mlogloss:0.654627\n",
      "[857]\teval-mlogloss:0.6543\n",
      "[858]\teval-mlogloss:0.653957\n",
      "[859]\teval-mlogloss:0.653608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[860]\teval-mlogloss:0.653279\n",
      "[861]\teval-mlogloss:0.652988\n",
      "[862]\teval-mlogloss:0.652661\n",
      "[863]\teval-mlogloss:0.652351\n",
      "[864]\teval-mlogloss:0.652019\n",
      "[865]\teval-mlogloss:0.651704\n",
      "[866]\teval-mlogloss:0.65138\n",
      "[867]\teval-mlogloss:0.651058\n",
      "[868]\teval-mlogloss:0.65074\n",
      "[869]\teval-mlogloss:0.650401\n",
      "[870]\teval-mlogloss:0.650089\n",
      "[871]\teval-mlogloss:0.649764\n",
      "[872]\teval-mlogloss:0.64943\n",
      "[873]\teval-mlogloss:0.649132\n",
      "[874]\teval-mlogloss:0.648803\n",
      "[875]\teval-mlogloss:0.648486\n",
      "[876]\teval-mlogloss:0.648202\n",
      "[877]\teval-mlogloss:0.647893\n",
      "[878]\teval-mlogloss:0.647587\n",
      "[879]\teval-mlogloss:0.647294\n",
      "[880]\teval-mlogloss:0.646962\n",
      "[881]\teval-mlogloss:0.646645\n",
      "[882]\teval-mlogloss:0.646333\n",
      "[883]\teval-mlogloss:0.646007\n",
      "[884]\teval-mlogloss:0.645715\n",
      "[885]\teval-mlogloss:0.64538\n",
      "[886]\teval-mlogloss:0.645086\n",
      "[887]\teval-mlogloss:0.644777\n",
      "[888]\teval-mlogloss:0.644463\n",
      "[889]\teval-mlogloss:0.644154\n",
      "[890]\teval-mlogloss:0.64383\n",
      "[891]\teval-mlogloss:0.643535\n",
      "[892]\teval-mlogloss:0.64321\n",
      "[893]\teval-mlogloss:0.642904\n",
      "[894]\teval-mlogloss:0.642583\n",
      "[895]\teval-mlogloss:0.642284\n",
      "[896]\teval-mlogloss:0.641974\n",
      "[897]\teval-mlogloss:0.641647\n",
      "[898]\teval-mlogloss:0.641348\n",
      "[899]\teval-mlogloss:0.641065\n",
      "[900]\teval-mlogloss:0.640739\n",
      "[901]\teval-mlogloss:0.640438\n",
      "[902]\teval-mlogloss:0.640136\n",
      "[903]\teval-mlogloss:0.639809\n",
      "[904]\teval-mlogloss:0.639498\n",
      "[905]\teval-mlogloss:0.639186\n",
      "[906]\teval-mlogloss:0.638868\n",
      "[907]\teval-mlogloss:0.638579\n",
      "[908]\teval-mlogloss:0.638291\n",
      "[909]\teval-mlogloss:0.637989\n",
      "[910]\teval-mlogloss:0.637658\n",
      "[911]\teval-mlogloss:0.637356\n",
      "[912]\teval-mlogloss:0.637077\n",
      "[913]\teval-mlogloss:0.636747\n",
      "[914]\teval-mlogloss:0.636434\n",
      "[915]\teval-mlogloss:0.636131\n",
      "[916]\teval-mlogloss:0.635836\n",
      "[917]\teval-mlogloss:0.635541\n",
      "[918]\teval-mlogloss:0.635245\n",
      "[919]\teval-mlogloss:0.634962\n",
      "[920]\teval-mlogloss:0.634647\n",
      "[921]\teval-mlogloss:0.634327\n",
      "[922]\teval-mlogloss:0.634015\n",
      "[923]\teval-mlogloss:0.633705\n",
      "[924]\teval-mlogloss:0.633395\n",
      "[925]\teval-mlogloss:0.633105\n",
      "[926]\teval-mlogloss:0.632777\n",
      "[927]\teval-mlogloss:0.632459\n",
      "[928]\teval-mlogloss:0.632166\n",
      "[929]\teval-mlogloss:0.631868\n",
      "[930]\teval-mlogloss:0.631532\n",
      "[931]\teval-mlogloss:0.631229\n",
      "[932]\teval-mlogloss:0.630941\n",
      "[933]\teval-mlogloss:0.630644\n",
      "[934]\teval-mlogloss:0.630356\n",
      "[935]\teval-mlogloss:0.630045\n",
      "[936]\teval-mlogloss:0.629651\n",
      "[937]\teval-mlogloss:0.629329\n",
      "[938]\teval-mlogloss:0.629012\n",
      "[939]\teval-mlogloss:0.628686\n",
      "[940]\teval-mlogloss:0.628385\n",
      "[941]\teval-mlogloss:0.628074\n",
      "[942]\teval-mlogloss:0.627766\n",
      "[943]\teval-mlogloss:0.627478\n",
      "[944]\teval-mlogloss:0.627154\n",
      "[945]\teval-mlogloss:0.626829\n",
      "[946]\teval-mlogloss:0.626511\n",
      "[947]\teval-mlogloss:0.626203\n",
      "[948]\teval-mlogloss:0.625881\n",
      "[949]\teval-mlogloss:0.625613\n",
      "[950]\teval-mlogloss:0.62533\n",
      "[951]\teval-mlogloss:0.625049\n",
      "[952]\teval-mlogloss:0.624747\n",
      "[953]\teval-mlogloss:0.624445\n",
      "[954]\teval-mlogloss:0.62413\n",
      "[955]\teval-mlogloss:0.623841\n",
      "[956]\teval-mlogloss:0.623524\n",
      "[957]\teval-mlogloss:0.623182\n",
      "[958]\teval-mlogloss:0.622864\n",
      "[959]\teval-mlogloss:0.622575\n",
      "[960]\teval-mlogloss:0.622313\n",
      "[961]\teval-mlogloss:0.622016\n",
      "[962]\teval-mlogloss:0.621724\n",
      "[963]\teval-mlogloss:0.621405\n",
      "[964]\teval-mlogloss:0.621116\n",
      "[965]\teval-mlogloss:0.620833\n",
      "[966]\teval-mlogloss:0.62055\n",
      "[967]\teval-mlogloss:0.620224\n",
      "[968]\teval-mlogloss:0.619922\n",
      "[969]\teval-mlogloss:0.619645\n",
      "[970]\teval-mlogloss:0.619364\n",
      "[971]\teval-mlogloss:0.619083\n",
      "[972]\teval-mlogloss:0.618792\n",
      "[973]\teval-mlogloss:0.618488\n",
      "[974]\teval-mlogloss:0.618187\n",
      "[975]\teval-mlogloss:0.617874\n",
      "[976]\teval-mlogloss:0.617583\n",
      "[977]\teval-mlogloss:0.617285\n",
      "[978]\teval-mlogloss:0.616962\n",
      "[979]\teval-mlogloss:0.616674\n",
      "[980]\teval-mlogloss:0.616365\n",
      "[981]\teval-mlogloss:0.616111\n",
      "[982]\teval-mlogloss:0.615812\n",
      "[983]\teval-mlogloss:0.615527\n",
      "[984]\teval-mlogloss:0.615254\n",
      "[985]\teval-mlogloss:0.614962\n",
      "[986]\teval-mlogloss:0.614686\n",
      "[987]\teval-mlogloss:0.614408\n",
      "[988]\teval-mlogloss:0.614151\n",
      "[989]\teval-mlogloss:0.613874\n",
      "[990]\teval-mlogloss:0.613613\n",
      "[991]\teval-mlogloss:0.613332\n",
      "[992]\teval-mlogloss:0.613036\n",
      "[993]\teval-mlogloss:0.612746\n",
      "[994]\teval-mlogloss:0.612481\n",
      "[995]\teval-mlogloss:0.612158\n",
      "[996]\teval-mlogloss:0.611895\n",
      "[997]\teval-mlogloss:0.611614\n",
      "[998]\teval-mlogloss:0.611342\n",
      "[999]\teval-mlogloss:0.61107\n",
      "[1000]\teval-mlogloss:0.61078\n",
      "[1001]\teval-mlogloss:0.610476\n",
      "[1002]\teval-mlogloss:0.610172\n",
      "[1003]\teval-mlogloss:0.60991\n",
      "[1004]\teval-mlogloss:0.609658\n",
      "[1005]\teval-mlogloss:0.609353\n",
      "[1006]\teval-mlogloss:0.609106\n",
      "[1007]\teval-mlogloss:0.608852\n",
      "[1008]\teval-mlogloss:0.608543\n",
      "[1009]\teval-mlogloss:0.608274\n",
      "[1010]\teval-mlogloss:0.607984\n",
      "[1011]\teval-mlogloss:0.607697\n",
      "[1012]\teval-mlogloss:0.607394\n",
      "[1013]\teval-mlogloss:0.607122\n",
      "[1014]\teval-mlogloss:0.606877\n",
      "[1015]\teval-mlogloss:0.606602\n",
      "[1016]\teval-mlogloss:0.60633\n",
      "[1017]\teval-mlogloss:0.606064\n",
      "[1018]\teval-mlogloss:0.605804\n",
      "[1019]\teval-mlogloss:0.605527\n",
      "[1020]\teval-mlogloss:0.60524\n",
      "[1021]\teval-mlogloss:0.604952\n",
      "[1022]\teval-mlogloss:0.604657\n",
      "[1023]\teval-mlogloss:0.60435\n",
      "[1024]\teval-mlogloss:0.604092\n",
      "[1025]\teval-mlogloss:0.60381\n",
      "[1026]\teval-mlogloss:0.603563\n",
      "[1027]\teval-mlogloss:0.603297\n",
      "[1028]\teval-mlogloss:0.603029\n",
      "[1029]\teval-mlogloss:0.602756\n",
      "[1030]\teval-mlogloss:0.602457\n",
      "[1031]\teval-mlogloss:0.602201\n",
      "[1032]\teval-mlogloss:0.601927\n",
      "[1033]\teval-mlogloss:0.601628\n",
      "[1034]\teval-mlogloss:0.601354\n",
      "[1035]\teval-mlogloss:0.601101\n",
      "[1036]\teval-mlogloss:0.600843\n",
      "[1037]\teval-mlogloss:0.600539\n",
      "[1038]\teval-mlogloss:0.600284\n",
      "[1039]\teval-mlogloss:0.600018\n",
      "[1040]\teval-mlogloss:0.599713\n",
      "[1041]\teval-mlogloss:0.599457\n",
      "[1042]\teval-mlogloss:0.599183\n",
      "[1043]\teval-mlogloss:0.59892\n",
      "[1044]\teval-mlogloss:0.598651\n",
      "[1045]\teval-mlogloss:0.598378\n",
      "[1046]\teval-mlogloss:0.598077\n",
      "[1047]\teval-mlogloss:0.597799\n",
      "[1048]\teval-mlogloss:0.597523\n",
      "[1049]\teval-mlogloss:0.59722\n",
      "[1050]\teval-mlogloss:0.59693\n",
      "[1051]\teval-mlogloss:0.596647\n",
      "[1052]\teval-mlogloss:0.596357\n",
      "[1053]\teval-mlogloss:0.596095\n",
      "[1054]\teval-mlogloss:0.595828\n",
      "[1055]\teval-mlogloss:0.595536\n",
      "[1056]\teval-mlogloss:0.595264\n",
      "[1057]\teval-mlogloss:0.595011\n",
      "[1058]\teval-mlogloss:0.594756\n",
      "[1059]\teval-mlogloss:0.594494\n",
      "[1060]\teval-mlogloss:0.594216\n",
      "[1061]\teval-mlogloss:0.593962\n",
      "[1062]\teval-mlogloss:0.593719\n",
      "[1063]\teval-mlogloss:0.593435\n",
      "[1064]\teval-mlogloss:0.593144\n",
      "[1065]\teval-mlogloss:0.592867\n",
      "[1066]\teval-mlogloss:0.59256\n",
      "[1067]\teval-mlogloss:0.592297\n",
      "[1068]\teval-mlogloss:0.592011\n",
      "[1069]\teval-mlogloss:0.591736\n",
      "[1070]\teval-mlogloss:0.591458\n",
      "[1071]\teval-mlogloss:0.591182\n",
      "[1072]\teval-mlogloss:0.590899\n",
      "[1073]\teval-mlogloss:0.590614\n",
      "[1074]\teval-mlogloss:0.590351\n",
      "[1075]\teval-mlogloss:0.590092\n",
      "[1076]\teval-mlogloss:0.589825\n",
      "[1077]\teval-mlogloss:0.589568\n",
      "[1078]\teval-mlogloss:0.589313\n",
      "[1079]\teval-mlogloss:0.589047\n",
      "[1080]\teval-mlogloss:0.58878\n",
      "[1081]\teval-mlogloss:0.588532\n",
      "[1082]\teval-mlogloss:0.588256\n",
      "[1083]\teval-mlogloss:0.587983\n",
      "[1084]\teval-mlogloss:0.587729\n",
      "[1085]\teval-mlogloss:0.587481\n",
      "[1086]\teval-mlogloss:0.587222\n",
      "[1087]\teval-mlogloss:0.58695\n",
      "[1088]\teval-mlogloss:0.586695\n",
      "[1089]\teval-mlogloss:0.586409\n",
      "[1090]\teval-mlogloss:0.586152\n",
      "[1091]\teval-mlogloss:0.585902\n",
      "[1092]\teval-mlogloss:0.585622\n",
      "[1093]\teval-mlogloss:0.585341\n",
      "[1094]\teval-mlogloss:0.585081\n",
      "[1095]\teval-mlogloss:0.584823\n",
      "[1096]\teval-mlogloss:0.584564\n",
      "[1097]\teval-mlogloss:0.584314\n",
      "[1098]\teval-mlogloss:0.584022\n",
      "[1099]\teval-mlogloss:0.583763\n",
      "[1100]\teval-mlogloss:0.58352\n",
      "[1101]\teval-mlogloss:0.583218\n",
      "[1102]\teval-mlogloss:0.582959\n",
      "[1103]\teval-mlogloss:0.582688\n",
      "[1104]\teval-mlogloss:0.582414\n",
      "[1105]\teval-mlogloss:0.582125\n",
      "[1106]\teval-mlogloss:0.581885\n",
      "[1107]\teval-mlogloss:0.581601\n",
      "[1108]\teval-mlogloss:0.58136\n",
      "[1109]\teval-mlogloss:0.581107\n",
      "[1110]\teval-mlogloss:0.580857\n",
      "[1111]\teval-mlogloss:0.580576\n",
      "[1112]\teval-mlogloss:0.580341\n",
      "[1113]\teval-mlogloss:0.580059\n",
      "[1114]\teval-mlogloss:0.579825\n",
      "[1115]\teval-mlogloss:0.579575\n",
      "[1116]\teval-mlogloss:0.579321\n",
      "[1117]\teval-mlogloss:0.579075\n",
      "[1118]\teval-mlogloss:0.578804\n",
      "[1119]\teval-mlogloss:0.578554\n",
      "[1120]\teval-mlogloss:0.578311\n",
      "[1121]\teval-mlogloss:0.578054\n",
      "[1122]\teval-mlogloss:0.577791\n",
      "[1123]\teval-mlogloss:0.577564\n",
      "[1124]\teval-mlogloss:0.577309\n",
      "[1125]\teval-mlogloss:0.577069\n",
      "[1126]\teval-mlogloss:0.57682\n",
      "[1127]\teval-mlogloss:0.576566\n",
      "[1128]\teval-mlogloss:0.576276\n",
      "[1129]\teval-mlogloss:0.576015\n",
      "[1130]\teval-mlogloss:0.575772\n",
      "[1131]\teval-mlogloss:0.575533\n",
      "[1132]\teval-mlogloss:0.575285\n",
      "[1133]\teval-mlogloss:0.575\n",
      "[1134]\teval-mlogloss:0.574749\n",
      "[1135]\teval-mlogloss:0.574511\n",
      "[1136]\teval-mlogloss:0.574269\n",
      "[1137]\teval-mlogloss:0.574004\n",
      "[1138]\teval-mlogloss:0.573775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1139]\teval-mlogloss:0.573529\n",
      "[1140]\teval-mlogloss:0.573285\n",
      "[1141]\teval-mlogloss:0.573002\n",
      "[1142]\teval-mlogloss:0.572751\n",
      "[1143]\teval-mlogloss:0.57251\n",
      "[1144]\teval-mlogloss:0.57226\n",
      "[1145]\teval-mlogloss:0.571981\n",
      "[1146]\teval-mlogloss:0.571747\n",
      "[1147]\teval-mlogloss:0.571475\n",
      "[1148]\teval-mlogloss:0.571206\n",
      "[1149]\teval-mlogloss:0.570947\n",
      "[1150]\teval-mlogloss:0.570709\n",
      "[1151]\teval-mlogloss:0.570468\n",
      "[1152]\teval-mlogloss:0.570225\n",
      "[1153]\teval-mlogloss:0.569997\n",
      "[1154]\teval-mlogloss:0.569727\n",
      "[1155]\teval-mlogloss:0.569462\n",
      "[1156]\teval-mlogloss:0.569225\n",
      "[1157]\teval-mlogloss:0.568986\n",
      "[1158]\teval-mlogloss:0.568735\n",
      "[1159]\teval-mlogloss:0.568494\n",
      "[1160]\teval-mlogloss:0.568243\n",
      "[1161]\teval-mlogloss:0.56797\n",
      "[1162]\teval-mlogloss:0.567673\n",
      "[1163]\teval-mlogloss:0.567414\n",
      "[1164]\teval-mlogloss:0.567172\n",
      "[1165]\teval-mlogloss:0.566905\n",
      "[1166]\teval-mlogloss:0.566659\n",
      "[1167]\teval-mlogloss:0.566385\n",
      "[1168]\teval-mlogloss:0.566141\n",
      "[1169]\teval-mlogloss:0.565905\n",
      "[1170]\teval-mlogloss:0.565683\n",
      "[1171]\teval-mlogloss:0.565425\n",
      "[1172]\teval-mlogloss:0.565182\n",
      "[1173]\teval-mlogloss:0.564917\n",
      "[1174]\teval-mlogloss:0.564678\n",
      "[1175]\teval-mlogloss:0.564435\n",
      "[1176]\teval-mlogloss:0.564178\n",
      "[1177]\teval-mlogloss:0.563909\n",
      "[1178]\teval-mlogloss:0.563684\n",
      "[1179]\teval-mlogloss:0.563433\n",
      "[1180]\teval-mlogloss:0.563179\n",
      "[1181]\teval-mlogloss:0.562938\n",
      "[1182]\teval-mlogloss:0.562666\n",
      "[1183]\teval-mlogloss:0.562424\n",
      "[1184]\teval-mlogloss:0.562141\n",
      "[1185]\teval-mlogloss:0.561902\n",
      "[1186]\teval-mlogloss:0.561657\n",
      "[1187]\teval-mlogloss:0.561407\n",
      "[1188]\teval-mlogloss:0.561134\n",
      "[1189]\teval-mlogloss:0.560863\n",
      "[1190]\teval-mlogloss:0.560614\n",
      "[1191]\teval-mlogloss:0.560392\n",
      "[1192]\teval-mlogloss:0.560072\n",
      "[1193]\teval-mlogloss:0.559807\n",
      "[1194]\teval-mlogloss:0.559557\n",
      "[1195]\teval-mlogloss:0.559322\n",
      "[1196]\teval-mlogloss:0.559054\n",
      "[1197]\teval-mlogloss:0.55881\n",
      "[1198]\teval-mlogloss:0.558545\n",
      "[1199]\teval-mlogloss:0.558294\n",
      "[1200]\teval-mlogloss:0.558058\n",
      "[1201]\teval-mlogloss:0.557815\n",
      "[1202]\teval-mlogloss:0.557594\n",
      "[1203]\teval-mlogloss:0.557348\n",
      "[1204]\teval-mlogloss:0.557093\n",
      "[1205]\teval-mlogloss:0.556868\n",
      "[1206]\teval-mlogloss:0.556645\n",
      "[1207]\teval-mlogloss:0.556352\n",
      "[1208]\teval-mlogloss:0.556083\n",
      "[1209]\teval-mlogloss:0.555831\n",
      "[1210]\teval-mlogloss:0.555571\n",
      "[1211]\teval-mlogloss:0.555338\n",
      "[1212]\teval-mlogloss:0.555125\n",
      "[1213]\teval-mlogloss:0.55487\n",
      "[1214]\teval-mlogloss:0.554636\n",
      "[1215]\teval-mlogloss:0.554422\n",
      "[1216]\teval-mlogloss:0.554213\n",
      "[1217]\teval-mlogloss:0.553954\n",
      "[1218]\teval-mlogloss:0.553705\n",
      "[1219]\teval-mlogloss:0.553469\n",
      "[1220]\teval-mlogloss:0.553238\n",
      "[1221]\teval-mlogloss:0.553013\n",
      "[1222]\teval-mlogloss:0.55276\n",
      "[1223]\teval-mlogloss:0.55252\n",
      "[1224]\teval-mlogloss:0.552297\n",
      "[1225]\teval-mlogloss:0.552071\n",
      "[1226]\teval-mlogloss:0.551818\n",
      "[1227]\teval-mlogloss:0.551592\n",
      "[1228]\teval-mlogloss:0.55138\n",
      "[1229]\teval-mlogloss:0.551156\n",
      "[1230]\teval-mlogloss:0.550927\n",
      "[1231]\teval-mlogloss:0.550711\n",
      "[1232]\teval-mlogloss:0.550467\n",
      "[1233]\teval-mlogloss:0.550224\n",
      "[1234]\teval-mlogloss:0.549972\n",
      "[1235]\teval-mlogloss:0.549683\n",
      "[1236]\teval-mlogloss:0.549454\n",
      "[1237]\teval-mlogloss:0.549219\n",
      "[1238]\teval-mlogloss:0.54897\n",
      "[1239]\teval-mlogloss:0.548738\n",
      "[1240]\teval-mlogloss:0.548499\n",
      "[1241]\teval-mlogloss:0.548246\n",
      "[1242]\teval-mlogloss:0.548022\n",
      "[1243]\teval-mlogloss:0.547806\n",
      "[1244]\teval-mlogloss:0.547589\n",
      "[1245]\teval-mlogloss:0.547379\n",
      "[1246]\teval-mlogloss:0.547131\n",
      "[1247]\teval-mlogloss:0.546904\n",
      "[1248]\teval-mlogloss:0.546673\n",
      "[1249]\teval-mlogloss:0.546429\n",
      "[1250]\teval-mlogloss:0.546182\n",
      "[1251]\teval-mlogloss:0.545919\n",
      "[1252]\teval-mlogloss:0.545686\n",
      "[1253]\teval-mlogloss:0.545435\n",
      "[1254]\teval-mlogloss:0.545204\n",
      "[1255]\teval-mlogloss:0.544985\n",
      "[1256]\teval-mlogloss:0.544729\n",
      "[1257]\teval-mlogloss:0.544464\n",
      "[1258]\teval-mlogloss:0.544248\n",
      "[1259]\teval-mlogloss:0.544025\n",
      "[1260]\teval-mlogloss:0.543793\n",
      "[1261]\teval-mlogloss:0.543575\n",
      "[1262]\teval-mlogloss:0.543358\n",
      "[1263]\teval-mlogloss:0.543131\n",
      "[1264]\teval-mlogloss:0.542918\n",
      "[1265]\teval-mlogloss:0.542633\n",
      "[1266]\teval-mlogloss:0.54242\n",
      "[1267]\teval-mlogloss:0.542206\n",
      "[1268]\teval-mlogloss:0.541978\n",
      "[1269]\teval-mlogloss:0.541765\n",
      "[1270]\teval-mlogloss:0.541513\n",
      "[1271]\teval-mlogloss:0.541286\n",
      "[1272]\teval-mlogloss:0.541061\n",
      "[1273]\teval-mlogloss:0.540836\n",
      "[1274]\teval-mlogloss:0.540602\n",
      "[1275]\teval-mlogloss:0.540371\n",
      "[1276]\teval-mlogloss:0.540152\n",
      "[1277]\teval-mlogloss:0.539933\n",
      "[1278]\teval-mlogloss:0.539722\n",
      "[1279]\teval-mlogloss:0.539509\n",
      "[1280]\teval-mlogloss:0.539264\n",
      "[1281]\teval-mlogloss:0.539045\n",
      "[1282]\teval-mlogloss:0.53882\n",
      "[1283]\teval-mlogloss:0.538608\n",
      "[1284]\teval-mlogloss:0.538394\n",
      "[1285]\teval-mlogloss:0.538181\n",
      "[1286]\teval-mlogloss:0.537945\n",
      "[1287]\teval-mlogloss:0.537702\n",
      "[1288]\teval-mlogloss:0.537436\n",
      "[1289]\teval-mlogloss:0.537218\n",
      "[1290]\teval-mlogloss:0.537004\n",
      "[1291]\teval-mlogloss:0.536801\n",
      "[1292]\teval-mlogloss:0.536569\n",
      "[1293]\teval-mlogloss:0.536309\n",
      "[1294]\teval-mlogloss:0.536073\n",
      "[1295]\teval-mlogloss:0.535849\n",
      "[1296]\teval-mlogloss:0.535631\n",
      "[1297]\teval-mlogloss:0.535367\n",
      "[1298]\teval-mlogloss:0.535121\n",
      "[1299]\teval-mlogloss:0.534912\n",
      "[1300]\teval-mlogloss:0.534672\n",
      "[1301]\teval-mlogloss:0.534433\n",
      "[1302]\teval-mlogloss:0.534225\n",
      "[1303]\teval-mlogloss:0.53399\n",
      "[1304]\teval-mlogloss:0.533764\n",
      "[1305]\teval-mlogloss:0.53355\n",
      "[1306]\teval-mlogloss:0.533312\n",
      "[1307]\teval-mlogloss:0.533076\n",
      "[1308]\teval-mlogloss:0.532817\n",
      "[1309]\teval-mlogloss:0.532577\n",
      "[1310]\teval-mlogloss:0.53235\n",
      "[1311]\teval-mlogloss:0.532112\n",
      "[1312]\teval-mlogloss:0.531906\n",
      "[1313]\teval-mlogloss:0.531687\n",
      "[1314]\teval-mlogloss:0.531495\n",
      "[1315]\teval-mlogloss:0.531285\n",
      "[1316]\teval-mlogloss:0.531033\n",
      "[1317]\teval-mlogloss:0.530817\n",
      "[1318]\teval-mlogloss:0.530562\n",
      "[1319]\teval-mlogloss:0.53035\n",
      "[1320]\teval-mlogloss:0.530076\n",
      "[1321]\teval-mlogloss:0.529833\n",
      "[1322]\teval-mlogloss:0.529599\n",
      "[1323]\teval-mlogloss:0.52938\n",
      "[1324]\teval-mlogloss:0.529167\n",
      "[1325]\teval-mlogloss:0.52897\n",
      "[1326]\teval-mlogloss:0.528741\n",
      "[1327]\teval-mlogloss:0.528523\n",
      "[1328]\teval-mlogloss:0.528284\n",
      "[1329]\teval-mlogloss:0.528038\n",
      "[1330]\teval-mlogloss:0.52785\n",
      "[1331]\teval-mlogloss:0.527611\n",
      "[1332]\teval-mlogloss:0.527393\n",
      "[1333]\teval-mlogloss:0.527202\n",
      "[1334]\teval-mlogloss:0.526993\n",
      "[1335]\teval-mlogloss:0.526773\n",
      "[1336]\teval-mlogloss:0.526553\n",
      "[1337]\teval-mlogloss:0.526344\n",
      "[1338]\teval-mlogloss:0.526142\n",
      "[1339]\teval-mlogloss:0.525901\n",
      "[1340]\teval-mlogloss:0.525698\n",
      "[1341]\teval-mlogloss:0.525496\n",
      "[1342]\teval-mlogloss:0.525273\n",
      "[1343]\teval-mlogloss:0.525007\n",
      "[1344]\teval-mlogloss:0.524804\n",
      "[1345]\teval-mlogloss:0.52458\n",
      "[1346]\teval-mlogloss:0.524366\n",
      "[1347]\teval-mlogloss:0.524135\n",
      "[1348]\teval-mlogloss:0.523926\n",
      "[1349]\teval-mlogloss:0.523724\n",
      "[1350]\teval-mlogloss:0.523515\n",
      "[1351]\teval-mlogloss:0.5233\n",
      "[1352]\teval-mlogloss:0.523075\n",
      "[1353]\teval-mlogloss:0.52287\n",
      "[1354]\teval-mlogloss:0.522679\n",
      "[1355]\teval-mlogloss:0.522453\n",
      "[1356]\teval-mlogloss:0.522228\n",
      "[1357]\teval-mlogloss:0.522005\n",
      "[1358]\teval-mlogloss:0.52181\n",
      "[1359]\teval-mlogloss:0.521595\n",
      "[1360]\teval-mlogloss:0.521396\n",
      "[1361]\teval-mlogloss:0.521187\n",
      "[1362]\teval-mlogloss:0.520973\n",
      "[1363]\teval-mlogloss:0.520758\n",
      "[1364]\teval-mlogloss:0.520554\n",
      "[1365]\teval-mlogloss:0.520353\n",
      "[1366]\teval-mlogloss:0.520117\n",
      "[1367]\teval-mlogloss:0.519922\n",
      "[1368]\teval-mlogloss:0.519701\n",
      "[1369]\teval-mlogloss:0.519501\n",
      "[1370]\teval-mlogloss:0.519301\n",
      "[1371]\teval-mlogloss:0.519069\n",
      "[1372]\teval-mlogloss:0.518838\n",
      "[1373]\teval-mlogloss:0.518623\n",
      "[1374]\teval-mlogloss:0.51842\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1345-0ba0ca985c2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mevallist\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnum_round\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mgbm_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_round\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevallist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m--> 894\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m    895\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(x_train[:,rf.feature_importances_>0.0005], label=y_train_trend)\n",
    "dtest = xgb.DMatrix(x_test[:,rf.feature_importances_>0.0005], label=y_test_trend)\n",
    "\n",
    "params = {\"objective\": \"multi:softmax\", \"booster\":\"gbtree\", 'max_depth':'2', 'eta':'0.001', 'subsample':'0.7', 'eval_metric':'mlogloss' , 'verbose':0, 'num_class':3}\n",
    "params['nthread'] = 4  \n",
    "evallist  = [(dtest,'eval')]\n",
    "num_round = 5000\n",
    "gbm_1 = xgb.train(params, dtrain, num_round, evallist)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 22   0   8]\n",
      " [  0  50   3]\n",
      " [ 16   2 192]]\n",
      "0.8430739527449398\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "print(confusion_matrix(gbm_1.predict(dtest), y_test_trend))\n",
    "print(f1_score(gbm_1.predict(dtest), y_test_trend, average='macro')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1220,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Booster' object has no attribute 'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1220-fc5ba8aa3128>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgbm_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Booster' object has no attribute 'predict_proba'"
     ]
    }
   ],
   "source": [
    "gbm_1.predict_proba(dtest)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
